\chapter{Procedimento adotado} \label{procedimento_adotado}

Neste capítulo, o procedimento adotado ao longo do trabalho é detalhado com o intuito de permitir ao leitor compreender melhor a lógica por trás de algumas escolhas feitas no decorrer do trabalho e de explorar alguns detalhes importantes da implementação dos módulos de programação.

\section{Conjunto de dados}

Como descrito na introdução, o intuito deste trabalho foi elaborar um projeto que utilizasse aprendizado de máquinas e proporcionasse alguma utilidade prática. Para isso, foi necessária a escolha de um conjunto de dados que possibilitasse a criação de uma aplicação completa com base em aprendizado de máquinas em tempo útil para a realização deste trabalho. Tendo isso em mente, a decisão recaiu sobre um conjunto de dados\cite{larxel_dataset} originado de um artigo científico\cite{chicco2020} voltado para o estudo de aprendizado de máquinas para a previsão de ocorrência de insuficiência cardíaca.

O conjunto de dados escolhido\cite{larxel_dataset} contém 299 registros de pacientes, cada um consistindo em 11 parâmetros relacionados à saúde geral e cardíaca de um paciente, 1 parâmetro indicando o tempo de acompanhamento médico do paciente e 1 resultado indicando se o paciente veio à óbito durante o acompanhamento realizado. Dessa forma, trata-se de um conjunto de dados pequeno, de fácil compreensão, que pudesse ser explorado com um certo grau de profundidade em um curto espaço de tempo, e com uma clara utilidade prática de auxiliar a prevenção da ocorrência de insuficiência cardíaca em pacientes com base em uma previsão realizada por meio de aprendizado de máquinas.

Além das características úteis do conjunto de dados em si para a realização deste trabalho, o artigo científico que originou o conjunto de dados\cite{chicco2020} consiste em um ótimo estudo comparativo do desempenho de diferentes tipos de modelos de dados na previsão de insuficiência cardíaca com base no conjunto de dados em si, proporcionando uma referência útil para a realização de escolhas do tipo de modelo de aprendizado de máquinas a ser utilizado no conjunto de dados e para a comparação dos resultados atingidos no treinamento de modelos de aprendizado de máquinas.

Apesar dessas excelentes qualidades, devemos ressaltar que o conjunto de dados escolhido não é sem falhas. A baixa quantidade de registros no conjunto de dados faz com que o treinamento de modelos de aprendizado de máquinas seja extremamente suscetível à \textit{overfitting}, resultando em um modelo que não forneça bons resultados em aplicações práticas. Também podemos notar que a baixa quantidade de registros em que o paciente veio à óbito, agravada pelas subdivisões do conjunto de dados em dados de treinamento, de teste e de validação, pode gerar modelos com um viés para previsões positivas, aumentando a probabilidade de que o modelo de aprendizado de máquinas gere falsos negativos, em que o sistema não prediz a insuficiência cardíaca e o paciente vem à óbito. A forma como essas limitações da base de dados foram tratadas será descrita posteriormente.

\section{Modelos de treinamento}

Com a escolha do conjunto de dados feita, o próximo passo seria definir quais tipos de modelos de treinamento de aprendizagem de máquinas seriam avaliados para uso na aplicação e estabelecer um método específico de avaliação para permitir a comparação entre os diferentes modelos de treinamento e determinar qual deveria ser utilizado na aplicação.

\subsection{Tipos de modelos testados}

Inicialmente, o autor pretendia avaliar o desempenho apenas de modelos do tipo redes neuronais de perceptron multicamada por ter maior familiaridade com esse tipo de modelo. Entretanto, a leitura da análise realizada e dos resultados obtidos no artigo científico\cite{chicco2020} que originou o conjunto de dados utilizado\cite{larxel_dataset}, bem como o tempo necessário para o treinamento de um único modelo de perceptron multicamada, levaram o autor a avaliar também modelos do tipo florestas randômicas, os quais obtiveram a melhor acurácia de previsão de acordo com os resultados do artigo científico mencionado e podem ser treinados em uma fração do tempo de treinamento de modelos do tipo perceptron multicamada.

\subsection{Método de avaliação dos modelos de treinamento de aprendizado de máquinas}

Com o intuito de comparar diferentes modelos de treinamento de aprendizado de máquinas, um método padrão de avaliação foi adotado com base no método utilizado no artigo científico\cite{chicco2020} mencionado. Esta subseção, com o intuito de justificar algumas das escolhas feitas na montagem do método de avaliação adotado, descreve formalmente tanto o método de avaliação de modelos de treinamento utilizado no artigo científico, como o método de treinamento utilizado neste trabalho.

\subsubsection{Método de avaliação de modelos de treinamento utilizado no artigo científico}

O artigo científico\cite{chicco2020} em que o conjunto de dados\cite{larxel_dataset} foi primeiramente apresentado e que buscou estudar vários aspectos do aprendizado de máquinas aplicado ao conjunto de dados utilizou um método específico para avaliar quais foram os melhores modelos de aprendizado de máquinas. Esse método consistiu em dois submétodos diferentes para modelos com otimização de hiper-parâmetros e para modelos sem otimização de hiper-parâmetros.

Para tipos de modelos com otimização de hiper-parâmetros, o conjunto de dados foi dividido em 60\% de dados para treinamento, 20\% de dados para validação e 20\% de dados para teste. Primeiramente, vários modelos com diferentes hiper-parâmetros foram treinados com o subconjunto de dados de treinamento com o intuito de encontrar o conjunto de hiper-parâmetros que gerasse o melhor coeficiente de correlação de Matthews (MCC) relativo à previsão feita sobre o subconjunto de dados de validação. Esse conjunto de hiper-parâmetros então foi utilizado em um novo modelo, treinado com o subconjunto de dados de treinamento, para obter o coeficiente de correlação de Matthews (MCC) relativo à previsão feita sobre o subconjunto de dados de teste. Esse procedimento foi realizado sobre 100 diferentes partições do conjunto de dados, para que a média e mediana dos 100 resultados de coeficiente de correlação de Matthews (MCC) relativos às previsões feitas sobre os subconjuntos de dados de teste com aquele tipo de modelo fossem calculados.

Para tipos de modelos sem otimização de hiper-parâmetros, o conjunto de dados foi dividido em 80\% de dados para treinamento e 20\% de dados para teste. Um modelo foi treinado com o subconjunto de dados de treinamento para obter o coeficiente de correlação de Matthews (MCC) relativo à previsão feita sobre o subconjunto de dados de teste. Esse procedimento foi realizado sobre 100 diferentes partições do conjunto de dados, para que a média e mediana dos 100 resultados de coeficiente de correlação de Matthews (MCC) relativos às previsões feitas sobre os subconjuntos de dados de teste com aquele tipo de modelo fossem calculados.

\subsubsection{Método de avaliação de modelos de treinamento utilizado neste trabalho}

Neste trabalho, o método utilizado para avaliar quais modelos de treinamento obtiveram os melhores resultados se baseou no método de avaliação utilizado no artigo científico\cite{chicco2020}, mas com algumas alterações.

Em primeiro lugar, 100 inteiros de 32 bits sem sinal foram gerados e armazenados em um arquivo para serem utilizados como sementes na aleatoriedade inerente ao particionamento do conjunto de dados\cite{larxel_dataset}, de forma que todos os modelos agora utilizam as mesmas partições do conjunto de dados para realizarem seu treinamento e obterem seus resultados de validação e teste. Essa mudança foi feita com o intuito de permitir a replicação dos resultados obtidos e proporcionar uma forma mais justa de comparação entre diferentes modelos com diferentes hiper-parâmetros. Além disso, como o tempo de treinamento de alguns modelos pode ser consideravelmente longo, esse técnica permite que a obtenção de um resultado de validação ou teste para um mesmo modelo seja dividida em mais de uma execução, dado que um subconjunto de dados de validação e teste é fixo para uma dada semente escolhida.

Em segundo lugar, a otimização de hiper-parâmetros não pôde ser feita da mesma forma que o artigo científico, pois a quantidade de combinações de hiper-parâmetros existente não permitiria que todas as variações de hiper-parâmetros fossem testadas para um dado modelo e uma dada partição do conjunto de dados. Dessa forma, decidiu-se que a única otimização de hiper-parâmetros feita seria na quantidade de épocas de treinamento para modelos do tipo perceptron multicamada. O número de épocas escolhido para treinamento na obtenção dos resultados de teste será equivalente à época em que o modelo teve a menor perda nos dados de validação (\textit{early stopping}). Para os demais parâmetros, decidiu-se adotar o seguinte procedimento: várias variações de hiper-parâmetros seriam utilizadas para se obter o resultado de predição sobre os subconjuntos de validação do primeiro quinto das partições de dados disponíveis (20), e as combinações de hiper-parâmetros com os resultados mais promissores (mais especificamente, os modelos que estiveram entre os melhores 20\%) em relação ao subconjunto de validação seriam testadas sobre todos os subconjuntos de teste disponíveis (100) com o intuito de se calcular os seus resultados de predição. Isso permitiria que uma gigantesca quantidade de variações de hiper-parâmetros fosse experimentada para cada modelo, com apenas as variações de hiper-parâmetros mais promissoras sendo realmente testadas em todas as 100 possíveis partições do conjunto de dados disponível. Além disso, como o escopo desse trabalho envolve menos a comparação de diferentes modelos e mais a busca por um único conjunto de hiper-parâmetros que forneça bons resultados, acredito que esse formato de análise seria mais adequado que aquele utilizado no artigo científico em que diferentes combinações de hiper-parâmetros poderiam ser utilizadas em diferentes partições de dados no cálculo do resultado de teste de um modelo.

A medida utilizada para medir o desempenho de um modelo (nos resultados de validação e teste) foi a média da acurácia (accuracy) obtida em cada particionamento do conjunto de dados, em oposição ao uso do coeficiente de correlação de Matthews (MCC) utilizado no artigo científico.

Portanto, podemos resumir o procedimento adotado neste trabalho como sendo, para um dado conjunto de modelos com diferentes hiper-parâmetros, a obtenção dos resultados de validação para o primeiro quinto das sementes disponíveis e o cálculo subsequente dos resultados de teste com todas as sementes disponíveis para os modelos entre os melhores 20\% no quesito melhor média de acurácia para os dados de validação. Os resultados de validação influenciariam na escolha de quais modelos seriam utilizados para o cálculo de resultados de teste e também, no caso de modelos do tipo perceptron multicamada, na escolha do número de épocas de treinamento (\textit{early stopping}) para a obtenção de resultados de teste.

Por meio deste método de avaliação, espera-se que as falhas inerentes ao conjunto de dados utilizado sejam mitigadas. A utilização do critério de melhor média de acurácia na previsão de dados de 20 subconjuntos de validação e de 100 subconjuntos de teste é uma forma de se compensar a propensão a \textit{overfitting} e a viés no treinamento com esse conjunto de dados. Isso ocorre pois a existência de múltiplos subconjuntos distintos de treinamento assegura que os melhores modelos serão aqueles capazes de obter resultados consistentes na previsão de validação e de teste em diversos cenários, desfavorecendo combinações de hiper-parâmetros mais suscetíveis à geração de modelos que apresentem \textit{overfitting} e viés. Embora essa abordagem não solucione por completo as dificuldades apresentadas, sua utilização é um bom recurso na ausência de um conjunto de dados mais robusto e representativo da realidade.


%label cria um rótulo para o objeto, para permitir que ele seja referenciado com o comando \ref{nome-do-rotulo}


% Neste capítulo é apresentada uma arquitetura para provimento de comércio eletrônico
% para o Sistema Brasileiro de TV Digital (SBTVD) \nomenclature{SBTVD}{Sistema Brasileiro de TV Digital}. A mesma é uma arquitetura distribuída, baseada em componentes
% reutilizáveis, os \textit{Web Services}, conhecida como Arquitetura Orientada a Serviços.
%
% Segundo \cite{soares2007ginga}:
%
% \begin{quote}
% 	Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Ut purus elit, vesti- bulum ut, placerat ac, adipiscing vitae, felis. Curabitur dictum gravida mauris. Nam arcu libero, nonummy eget, consectetuer id, vulputate a, magna.
% \end{quote}
%
% Desta forma, a arquitetura proposta foi definida, incluindo a implementação de um \textit{framework} de comunicação (baseado nos protocolos HTTP e SOAP) que é apresentado sucintamente neste capítulo, e em mais detalhes no Capítulo \ref{capitulo2}. Mais detalhes podem ser consultados em \cite{soares2007ginga}. Veja um exemplo na Listagem \ref{list:server}, que foi adaptada de \url{http://manoelcampos.com}.
%
% Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Ut purus elit, vestibulum ut, placerat ac, adipiscing vitae, felis. Curabitur dictum gravida mauris. Nam arcu libero, no- nummy eget, consectetuer id, vulputate a, magna. Donec vehicula augue eu neque. Pel- lentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Mauris ut leo. Cras viverra metus rhoncus sem. Nulla et lectus vestibulum urna fringilla ultrices. Phasellus eu tellus sit amet tortor gravida placerat. Integer sapien est, iaculis in, pretium quis, viverra ac, nunc. Praesent eget sem vel leo ultrices bibendum. Aenean fauci- bus. Morbi dolor nulla, malesuada eu, pulvinar at, mollis ac, nulla. Curabitur auctor semper nulla. Donec varius orci eget risus. Duis nibh mi, congue eu, accumsan eleifend, sagittis quis, diam. Duis eget orci sit amet orci dignissim rutrum.
%
% Nulla malesuada porttitor diam. Donec felis erat, congue non, volutpat at, tincidunt tristi- que, libero. Vivamus viverra fermentum felis. Donec nonummy pellentesque ante. Phasellus adipiscing semper elit. Proin fermentum massa ac quam. Sed diam turpis, molestie vitae, placerat a, molestie nec, leo. Maecenas lacinia. Nam ipsum ligula, eleifend at, accumsan nec, suscipit a, ipsum. Morbi blandit ligula feugiat magna. Nunc eleifend consequat lorem. Sed lacinia nulla vitae enim. Pellentesque tincidunt purus vel magna. Integer non enim. Praesent euismod nunc eu purus. Donec bibendum quam in tellus. Nullam cursus pulvinar lectus. Donec et mi. Nam vulputate metus eu enim. Vestibulum pellentesque felis eu massa.
%
% \lstset{caption=Exemplo de aplicação servidora, label=list:server}
% \begin{lstlisting}[language=C]
% int main()
% {
%     FILE *fp;     int len;
%     static const int SIZE = 1024;
%     struct sockaddr_in me, target;
%     int sock=socket(AF_INET,SOCK_DGRAM,0);
%     char arquivo[SIZE];
%     me.sin_family=AF_INET;
%     me.sin_addr.s_addr=htonl(INADDR_ANY); // endereco IP local
%     me.sin_port=htons(0); // porta local (0=auto assign)
%     bind(sock,(struct sockaddr *)&me,sizeof(me));
%     target.sin_family=AF_INET;
%     target.sin_addr.s_addr=inet_addr("192.168.68.217"); // host local
%     target.sin_port=htons(8450); // porta de destino
%
%     if ((fp = fopen("video1.mp4","rb")) == NULL){
%         printf("Arquivo nao pode ser aberto.\n"); return -1;
%     }
%
%     while(!feof(fp)) {
%         len = fread(arquivo, 1, sizeof(arquivo), fp);
%         sendto(sock,arquivo,sizeof(arquivo),0,(struct sockaddr *)&target,sizeof(target));
%     }
%     sendto(sock,"FIM",sizeof("FIM"),0,(struct sockaddr *)&target,sizeof(target));
%     close(sock);
%     return 0;
% }
% \end{lstlisting}
